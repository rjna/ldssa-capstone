{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips to navigate the notebook: Everytime that you need to verify a claim made in the report, search for the corresponding section name. For some sections (mainly related with the model itself), the code can also be located in the notebook that contains the pipeline or in transformers.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score,precision_recall_curve\n",
    "from sklearn.base import TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from transformers import (\n",
    "    Test, \n",
    "    CreateCyclicalFeatures, \n",
    "    CategoricalDataCleaning, \n",
    "    NumericalDataCleaning\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VehicleSearchedIndicator</th>\n",
       "      <th>ContrabandIndicator</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>InterventionDateTime</th>\n",
       "      <th>InterventionLocationName</th>\n",
       "      <th>InterventionReasonCode</th>\n",
       "      <th>ReportingOfficerIdentificationID</th>\n",
       "      <th>ResidentIndicator</th>\n",
       "      <th>SearchAuthorizationCode</th>\n",
       "      <th>StatuteReason</th>\n",
       "      <th>SubjectAge</th>\n",
       "      <th>SubjectEthnicityCode</th>\n",
       "      <th>SubjectRaceCode</th>\n",
       "      <th>SubjectSexCode</th>\n",
       "      <th>TownResidentIndicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>10/01/2013 12:00:00 AM</td>\n",
       "      <td>NEW HAVEN</td>\n",
       "      <td>V</td>\n",
       "      <td>262</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>31.0</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>State Police</td>\n",
       "      <td>10/01/2013 12:00:00 AM</td>\n",
       "      <td>WILLINGTON</td>\n",
       "      <td>V</td>\n",
       "      <td>1000002715</td>\n",
       "      <td>False</td>\n",
       "      <td>N</td>\n",
       "      <td>Other</td>\n",
       "      <td>29.0</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>10/01/2013 12:00:00 AM</td>\n",
       "      <td>Terryville</td>\n",
       "      <td>V</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>Speed Related</td>\n",
       "      <td>18.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>10/01/2013 12:00:00 AM</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>V</td>\n",
       "      <td>D1</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>Speed Related</td>\n",
       "      <td>52.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Bethel</td>\n",
       "      <td>10/01/2013 12:00:00 AM</td>\n",
       "      <td>BETHEL</td>\n",
       "      <td>V</td>\n",
       "      <td>08M</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>Cell Phone</td>\n",
       "      <td>34.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VehicleSearchedIndicator  ContrabandIndicator Department Name  \\\n",
       "0                     False                False       New Haven   \n",
       "1                     False                False    State Police   \n",
       "2                     False                False        Plymouth   \n",
       "3                     False                False        Plymouth   \n",
       "4                     False                False          Bethel   \n",
       "\n",
       "     InterventionDateTime InterventionLocationName InterventionReasonCode  \\\n",
       "0  10/01/2013 12:00:00 AM                NEW HAVEN                      V   \n",
       "1  10/01/2013 12:00:00 AM               WILLINGTON                      V   \n",
       "2  10/01/2013 12:00:00 AM               Terryville                      V   \n",
       "3  10/01/2013 12:00:00 AM                 Plymouth                      V   \n",
       "4  10/01/2013 12:00:00 AM                   BETHEL                      V   \n",
       "\n",
       "  ReportingOfficerIdentificationID  ResidentIndicator SearchAuthorizationCode  \\\n",
       "0                              262               True                       N   \n",
       "1                       1000002715              False                       N   \n",
       "2                               21               True                       N   \n",
       "3                               D1               True                       N   \n",
       "4                              08M               True                       N   \n",
       "\n",
       "   StatuteReason  SubjectAge SubjectEthnicityCode SubjectRaceCode  \\\n",
       "0      Stop Sign        31.0                    H               W   \n",
       "1          Other        29.0                    M               W   \n",
       "2  Speed Related        18.0                    N               W   \n",
       "3  Speed Related        52.0                    N               W   \n",
       "4     Cell Phone        34.0                    N               W   \n",
       "\n",
       "  SubjectSexCode  TownResidentIndicator  \n",
       "0              M                   True  \n",
       "1              M                  False  \n",
       "2              M                   True  \n",
       "3              F                  False  \n",
       "4              M                  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data() -> pd.DataFrame:\n",
    "    \"\"\"Imports the data.\n",
    "    \n",
    "    Returns:\n",
    "        data (pd.DataFrame): DataFrame with the data. \n",
    "                             \n",
    "    \"\"\"\n",
    "    path = os.path.join('data', 'train.csv')\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "train_df = read_data()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.SubjectSexCode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train_df.groupby('SubjectSexCode')['VehicleSearchedIndicator'].sum().plot.barh(title = \"Number of Searched Vehicles by Sex Code\");\n",
    "ax.set_xlabel(\"Searched Vehicles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.SubjectRaceCode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('SubjectRaceCode')['VehicleSearchedIndicator'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "53524/2018931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22501/386325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "220/19746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "498/48641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.SubjectEthnicityCode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('SubjectEthnicityCode')['VehicleSearchedIndicator'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "876/45561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "58343/2099632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17524/328450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.ReportingOfficerIdentificationID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_searched_vehicles_by_officer = train_df.groupby(\"ReportingOfficerIdentificationID\")[\"VehicleSearchedIndicator\"].mean().reset_index()\n",
    "average_searched_vehicles_by_officer.columns = [\"ReportingOfficerIdentificationID\", \"VehicleSearchedIndicator\"]\n",
    "average_searched_vehicles_by_officer = average_searched_vehicles_by_officer.set_index('ReportingOfficerIdentificationID', drop=False)\n",
    "print(average_searched_vehicles_by_officer.VehicleSearchedIndicator.min())\n",
    "print(average_searched_vehicles_by_officer.VehicleSearchedIndicator.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_contraband_by_officer = train_df.groupby(\"ReportingOfficerIdentificationID\")[\"ContrabandIndicator\"].mean().reset_index()\n",
    "average_contraband_by_officer.columns = [\"ReportingOfficerIdentificationID\", \"ContrabandIndicator\"]\n",
    "average_contraband_by_officer = average_contraband_by_officer.set_index('ReportingOfficerIdentificationID', drop=False)\n",
    "print(average_contraband_by_officer.ContrabandIndicator.min())\n",
    "print(average_contraband_by_officer.ContrabandIndicator.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Department Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_searched_vehicles_by_department = train_df.groupby(\"Department Name\")[\"VehicleSearchedIndicator\"].mean().reset_index()\n",
    "average_searched_vehicles_by_department.columns = [\"Department Name\", \"VehicleSearchedIndicator\"]\n",
    "average_searched_vehicles_by_department = average_searched_vehicles_by_department.set_index('Department Name', drop=False)\n",
    "print(average_searched_vehicles_by_department.VehicleSearchedIndicator.min())\n",
    "print(average_searched_vehicles_by_department.VehicleSearchedIndicator.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_contraband_by_department = train_df.groupby(\"Department Name\")[\"ContrabandIndicator\"].mean().reset_index()\n",
    "average_contraband_by_department.columns = [\"Department Name\", \"ContrabandIndicator\"]\n",
    "average_contraband_by_department = average_contraband_by_department.set_index('Department Name', drop=False)\n",
    "print(average_contraband_by_department.ContrabandIndicator.min())\n",
    "print(average_contraband_by_department.ContrabandIndicator.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['InterventionDateTime'] = pd.to_datetime(train_df['InterventionDateTime'], format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['InterventionDateMonth'] = train_df['InterventionDateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_contraband_by_month = train_df.loc[train_df.VehicleSearchedIndicator == True].groupby(\"InterventionDateMonth\")[\"ContrabandIndicator\"].mean().reset_index()\n",
    "average_contraband_by_month.columns = [\"InterventionDateMonth\", \"ContrabandIndicator\"]\n",
    "average_contraband_by_month = average_contraband_by_month.set_index('InterventionDateMonth', drop=False)\n",
    "average_contraband_by_month.ContrabandIndicator.plot(label=\"ContrabandIndicator\", kind='barh')\n",
    "plt.xlabel('ContrabandIndicator')\n",
    "axis = plt.gca();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Business Question Analysis and Business questions technical support and Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_male = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"M\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"M\")].sum()\n",
    "precision_female = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"F\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"F\")].sum()\n",
    "precision_hispanic = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\")].sum()\n",
    "precision_middle_east = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\")].sum()\n",
    "precision_not_applicable_ethnicity = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\")].sum()\n",
    "precision_white = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"W\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"W\")].sum()\n",
    "precision_black = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"B\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"B\")].sum()\n",
    "precision_asian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"A\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"A\")].sum()\n",
    "precision_indian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"I\")].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"I\")].sum()\n",
    "print(precision_male, precision_female)\n",
    "print(precision_hispanic, precision_middle_east, precision_not_applicable_ethnicity)\n",
    "print(precision_white, precision_black, precision_asian, precision_indian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "for i in np.unique(train_df['Department Name'].values):\n",
    "    precision_male = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_female = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"F\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"F\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_hispanic = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_middle_east = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_not_applicable_ethnicity = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_white = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"W\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"W\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_black = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"B\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"B\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_indian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"I\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"I\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_asian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"A\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"A\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    test_list = [precision_male, precision_female]\n",
    "    test_list_2 = [precision_hispanic, precision_middle_east, precision_not_applicable_ethnicity]\n",
    "    test_list_3 = [precision_white, precision_black, precision_indian, precision_asian]\n",
    "    res = max(combinations(test_list, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "    res_2 = max(combinations(test_list_2, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "    res_3 = max(combinations(test_list_3, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "    if((abs(res[0]-res[1]) <= 0.05) & (abs(res_2[0]-res_2[1]) <= 0.05) & (abs(res_3[0]-res_3[1]) <= 0.05)):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_of_bigger_than_0dot9 = []\n",
    "for i in np.unique(train_df['Department Name'].values):\n",
    "    precision_male = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_female = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"F\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"F\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_hispanic = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_middle_east = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_not_applicable_ethnicity = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_white = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"W\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"W\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_black = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"B\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"B\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_indian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"I\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"I\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    precision_asian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"A\") & np.equal(train_df['Department Name'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"A\") & np.equal(train_df['Department Name'], i)].sum()\n",
    "    test_list = [precision_male, precision_female]\n",
    "    test_list_2 = [precision_hispanic, precision_middle_east, precision_not_applicable_ethnicity]\n",
    "    test_list_3 = [precision_white, precision_black, precision_indian, precision_asian]\n",
    "    res = max(combinations(test_list, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "    res_2 = max(combinations(test_list_2, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "    res_3 = max(combinations(test_list_3, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "    if(((abs(res[0]-res[1]) > 0.9)) | ((abs(res_2[0]-res_2[1]) > 0.9)) | ((abs(res_3[0]-res_3[1]) > 0.9))):\n",
    "        differences_of_bigger_than_0dot9.append(i)\n",
    "print(differences_of_bigger_than_0dot9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "differences_of_bigger_than_0dot9_officer = []\n",
    "ax = train_df['ReportingOfficerIdentificationID'].values\n",
    "ax = [str(i) for i in ax]\n",
    "ax = np.unique(ax)\n",
    "\n",
    "for i in ax:\n",
    "    if train_df.VehicleSearchedIndicator[np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum() > 100:\n",
    "        precision_male = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"M\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"M\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_female = train_df.ContrabandIndicator[np.equal(train_df.SubjectSexCode, \"F\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectSexCode, \"F\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_hispanic = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"H\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_middle_east = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"M\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_not_applicable_ethnicity = train_df.ContrabandIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectEthnicityCode, \"N\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_white = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"W\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"W\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_black = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"B\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"B\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_indian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"I\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"I\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        precision_asian = train_df.ContrabandIndicator[np.equal(train_df.SubjectRaceCode, \"A\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()/train_df.VehicleSearchedIndicator[np.equal(train_df.SubjectRaceCode, \"A\") & np.equal(train_df['ReportingOfficerIdentificationID'], i)].sum()\n",
    "        test_list = [precision_male, precision_female]\n",
    "        test_list_2 = [precision_hispanic, precision_middle_east, precision_not_applicable_ethnicity]\n",
    "        test_list_3 = [precision_white, precision_black, precision_indian, precision_asian]\n",
    "        res = max(combinations(test_list, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "        res_2 = max(combinations(test_list_2, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "        res_3 = max(combinations(test_list_3, 2), key = lambda sub: abs(sub[0]-sub[1]))\n",
    "        if(((abs(res[0]-res[1]) > 0.9) & ((abs(res[0]-res[1]) <= 1))) | ((abs(res_2[0]-res_2[1]) > 0.9) & (abs(res_2[0]-res_2[1]) <= 1)) | ((abs(res_3[0]-res_3[1]) > 0.9) & (abs(res_3[0]-res_3[1]) <=1))):\n",
    "            differences_of_bigger_than_0dot9_officer.append(i)\n",
    "print(differences_of_bigger_than_0dot9_officer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_global = train_df.ContrabandIndicator.sum()/train_df.VehicleSearchedIndicator.sum()\n",
    "precision_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Model expected outcomes overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['Department Name'] == 'WCSU'].SubjectEthnicityCode.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Model specifications.\n",
    "Regarding this section, the code is in the notebook that contains the pipeline and in transformers.py. Please note that some phrases (e.g. the binary encoder gave a little improvement in roc_auc compared to the ordinal encoder) can't be confirmed in the notebook. You will have to trust me on those claims :) both sources of code contain only the final version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Analysis of expected outcomes based on training set. The code is in the notebook that contains the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Alternatives considered. As described earlier, there is no code to prove this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Model Dataset technical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile list \n",
    "perc =[.20, .40, .60, .80] \n",
    "  \n",
    "# list of dtypes to include \n",
    "include =['float64']\n",
    "\n",
    "# calling describe method \n",
    "desc = train_df.describe(percentiles = perc, include = include) \n",
    "desc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_df.SubjectAge.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include =['object']\n",
    "  \n",
    "# calling describe method \n",
    "desc = train_df.describe(percentiles = perc, include = include) \n",
    "desc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include =['bool']\n",
    "  \n",
    "# calling describe method \n",
    "desc = train_df.describe(percentiles = perc, include = include) \n",
    "desc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.VehicleSearchedIndicator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7624/(237607+7624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.ContrabandIndicator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2839/(242392+2839)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.VehicleSearchedIndicator == True].ContrabandIndicator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2539/(5085+2539)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows_df = train_df[train_df.duplicated()]\n",
    "duplicate_rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "204756/2473643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inches_wide = 8\n",
    "inches_high = 8\n",
    "plt.rcParams[\"figure.figsize\"] = [inches_wide, inches_high]\n",
    "ax = train_df.SubjectAge.plot.hist(xlim=(0,100), bins=100, color='red', xticks = [0, 10, 16, 20, 40, 60, 80, 100], title = \"Age Distribution\");\n",
    "ax.set_xlabel(\"Age\")\n",
    "axis = plt.gca();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.VehicleSearchedIndicator == False].ContrabandIndicator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality = train_df.describe(exclude=np.number).T\n",
    "cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.SubjectEthnicityCode == 'M'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section Model technical analysis. Code is in the notebook that contains the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
